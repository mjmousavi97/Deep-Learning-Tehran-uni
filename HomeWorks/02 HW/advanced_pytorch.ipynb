{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqqnjHH3JVdFdHRabr3LKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjmousavi97/Deep-Learning-Tehran-uni/blob/main/HomeWorks/02%20HW/advanced_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "7--kvYcpUhfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # Core PyTorch library for tensors and GPU computations\n",
        "from torch import nn  # Module for building neural network layers\n",
        "import torch.nn.functional as F  # Functional API for layers and activations (stateless functions)\n",
        "from torch.utils.data import DataLoader, Dataset  # Tools for batching, shuffling, and creating custom datasets\n",
        "\n",
        "import torchvision  # PyTorch package for computer vision datasets, models, and transforms\n",
        "from torchvision import transforms  # Image preprocessing and transformations (resize, normalize, etc.)\n",
        "from torchvision.datasets import ImageFolder  # Loads images from folders organized by class labels\n",
        "\n",
        "import matplotlib.pyplot as plt  # Plotting graphs and displaying images\n",
        "import numpy as np  # Numerical computations and array operations\n",
        "import seaborn as sns  # Statistical data visualization\n",
        "import os  # File and directory operations\n",
        "import glob  # File path pattern matching (wildcards)\n",
        "import cv2  # OpenCV for image processing (reading, editing, filtering, etc.)\n",
        "from tqdm import tqdm  # Progress bar for loops\n",
        "from PIL import Image  # Pillow library for opening, saving, and manipulating images\n"
      ],
      "metadata": {
        "id": "JFjDsAxXUzV3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mounting Google Drive"
      ],
      "metadata": {
        "id": "3CNgmvyffNxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtdzjcG9fPxn",
        "outputId": "0d786479-4e17-4288-da04-2db11e3c9ab2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "xzTs9JVZS04N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_TRAIN = \"/content/drive/MyDrive/fashionmnist/train/\"\n",
        "DIR_TEST = \"/content/drive/MyDrive/fashionmnist/test/\""
      ],
      "metadata": {
        "id": "YDvL2o2GTnNe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = os.listdir(DIR_TRAIN)\n",
        "print(f\"Names of classes are: {classes}.\\nThere are {len(classes)} classes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LYgWvELUdw1",
        "outputId": "6d1619bc-9f90-4fc9-b529-014f750a1eda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names of classes are: ['Dress', 'Pullover', 'Sandal', 'Shirt', 'Sneaker', 'T-shirt', 'Trouser', 'Angle boot', 'Bag', 'Coat'].\n",
            "There are 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = []\n",
        "test_images = []\n",
        "\n",
        "for _class in classes:\n",
        "    train_images += glob.glob(DIR_TRAIN + _class + '/*.jpg')\n",
        "    test_images += glob.glob(DIR_TEST + _class + '/*.jpg')\n",
        "\n",
        "print(\"Total train images:\", len(train_images))\n",
        "print(\"Total test images:\", len(test_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6w59SoAkEop",
        "outputId": "b70600b2-4117-4bb0-d71b-5fdd89589a57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images: 60000\n",
            "Total test images: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=0.5, std=0.5)])"
      ],
      "metadata": {
        "id": "IRD6n9GxoXXF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root = \"data\", # where to download data to\n",
        "    train = True, # get training data\n",
        "    download = True, # download data if it doesn't exist on disk\n",
        "    transform = Transforms # images come as PIL format, we want to apply transform on them\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False, # get test data\n",
        "    download = True,\n",
        "    transform = Transforms\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPMwap19vk8N",
        "outputId": "4985fe81-3178-49b0-d395-b0d6be8c8b2f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 273kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.43MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 7.51MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataloader"
      ],
      "metadata": {
        "id": "TyaXLrw2vyAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=2,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "eZNDi_wuv24_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_batch, train_label_batch = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "xc-rMLvZ4HH8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sample_batch.shape, '\\n')\n",
        "print(train_label_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0KGXt314Zkr",
        "outputId": "a0edfbe0-3c2c-4798-dfc0-e63fd8d0b3ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28]) \n",
            "\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image = train_sample_batch[0].permute(1, 2, 0)\n",
        "label_of_sample_image = train_label_batch[0]\n",
        "\n",
        "mean, std = 0.5, 0.5\n",
        "sample_image = std * (sample_image + mean)\n",
        "\n",
        "plt.imshow(sample_image, cmap='grey')\n",
        "plt.axis('off')\n",
        "plt.title(f'A sample image of train data with label={classes[label_of_sample_image]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "NN7_F5mW4d6w",
        "outputId": "eb9bcb3a-15fd-4e19-b2f4-690d70497e11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'A sample image of train data with label=Coat')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Structure"
      ],
      "metadata": {
        "id": "vutHfpK157yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "[CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n",
        "\n"
      ],
      "metadata": {
        "id": "L4-CTTp1vxkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Convolutional Neural Network (CNN) model for image classification.\n",
        "\n",
        "    Architecture:\n",
        "    - Two convolutional layers each followed by Batch Normalization and ReLU activation.\n",
        "    - A MaxPooling layer to downsample the feature maps.\n",
        "    - A classifier consisting of Flatten, Dropout, and a Linear (fully connected) layer\n",
        "      to produce the final output.\n",
        "\n",
        "    Args:\n",
        "        input_channel (int): Number of input channels (e.g., 3 for RGB images).\n",
        "        hidden_unit (int): Number of filters (feature maps) in the convolutional layers.\n",
        "        output_shape (int): Number of classes or output features.\n",
        "\n",
        "    Forward pass:\n",
        "        - Input tensor of shape (batch_size, input_channel, height, width).\n",
        "        - Outputs raw logits of shape (batch_size, output_shape).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_channel, hidden_unit, output_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature extractor: convolutional block\n",
        "        self.CNN_block = nn.Sequential(\n",
        "            # First convolutional layer\n",
        "            nn.Conv2d(in_channels=input_channel, out_channels=hidden_unit, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=hidden_unit),  # Normalize activations for stability and faster convergence\n",
        "            nn.ReLU(inplace=True),                      # Non-linear activation\n",
        "\n",
        "            # Second convolutional layer\n",
        "            nn.Conv2d(in_channels=hidden_unit, out_channels=hidden_unit, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=hidden_unit),  # Batch normalization again\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # MaxPooling to reduce spatial dimensions by factor of 2\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Classifier: fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),       # Flatten feature maps into a vector\n",
        "            nn.Dropout(p=0.5),  # Dropout for regularization to prevent overfitting\n",
        "            nn.Linear(in_features=hidden_unit*14*14, out_features=output_shape)  # Final linear layer for classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Defines the forward computation of the network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, input_channel, height, width).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits of shape (batch_size, output_shape).\n",
        "        \"\"\"\n",
        "        x = self.CNN_block(x)    # Pass input through convolutional feature extractor\n",
        "        x = self.classifier(x)   # Pass extracted features through classifier\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HyU2AZaxv1xV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_Model(input_channel=1, hidden_unit=10, output_shape=len(classes))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fx9UI12GAhN",
        "outputId": "ee54b3da-0236-44e7-d0f8-e0e7ba503e6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Model(\n",
              "  (CNN_block): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): Linear(in_features=1960, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sample = torch.randn((1, 1, 28, 28))\n",
        "model(random_sample).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhdkaHZEGM_v",
        "outputId": "3ff2ebba-ecd1-4f75-a454-4912d76f5aa9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "wl5Tab4LHA8w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRH9EGguHHlU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}