{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjmousavi97/Deep-Learning-Tehran-uni/blob/main/HomeWorks/02%20HW/advanced_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7--kvYcpUhfK"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JFjDsAxXUzV3"
      },
      "outputs": [],
      "source": [
        "import torch  # Core PyTorch library for tensors and GPU computations\n",
        "from torch import nn  # Module for building neural network layers\n",
        "import torch.nn.functional as F  # Functional API for layers and activations (stateless functions)\n",
        "from torch.utils.data import DataLoader, Dataset  # Tools for batching, shuffling, and creating custom datasets\n",
        "\n",
        "import torchvision  # PyTorch package for computer vision datasets, models, and transforms\n",
        "from torchvision import transforms  # Image preprocessing and transformations (resize, normalize, etc.)\n",
        "from torchvision.datasets import ImageFolder  # Loads images from folders organized by class labels\n",
        "\n",
        "import matplotlib.pyplot as plt  # Plotting graphs and displaying images\n",
        "import numpy as np  # Numerical computations and array operations\n",
        "import seaborn as sns  # Statistical data visualization\n",
        "import os  # File and directory operations\n",
        "import glob  # File path pattern matching (wildcards)\n",
        "import cv2  # OpenCV for image processing (reading, editing, filtering, etc.)\n",
        "from tqdm import tqdm  # Progress bar for loops\n",
        "from PIL import Image  # Pillow library for opening, saving, and manipulating images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CNgmvyffNxb"
      },
      "source": [
        "#### Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtdzjcG9fPxn",
        "outputId": "b9291d0d-afca-49f1-ba46-7a1f8ee3cb93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzTs9JVZS04N"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YDvL2o2GTnNe"
      },
      "outputs": [],
      "source": [
        "DIR_TRAIN = \"/content/drive/MyDrive/fashionmnist/train/\"\n",
        "DIR_TEST = \"/content/drive/MyDrive/fashionmnist/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LYgWvELUdw1",
        "outputId": "9ba78454-1a1e-4764-c947-642f021c48d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names of classes are: ['Dress', 'Pullover', 'Sandal', 'Shirt', 'Sneaker', 'T-shirt', 'Trouser', 'Angle boot', 'Bag', 'Coat'].\n",
            "There are 10 classes.\n"
          ]
        }
      ],
      "source": [
        "classes = os.listdir(DIR_TRAIN)\n",
        "print(f\"Names of classes are: {classes}.\\nThere are {len(classes)} classes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6w59SoAkEop",
        "outputId": "43cf3cea-eb2d-416f-914e-cb9e03b3b80f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train images: 60000\n",
            "Total test images: 10000\n"
          ]
        }
      ],
      "source": [
        "train_images = []\n",
        "test_images = []\n",
        "\n",
        "for _class in classes:\n",
        "    train_images += glob.glob(DIR_TRAIN + _class + '/*.jpg')\n",
        "    test_images += glob.glob(DIR_TEST + _class + '/*.jpg')\n",
        "\n",
        "print(\"Total train images:\", len(train_images))\n",
        "print(\"Total test images:\", len(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IRD6n9GxoXXF"
      },
      "outputs": [],
      "source": [
        "Transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=0.5, std=0.5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XPMwap19vk8N"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root = \"data\", # where to download data to\n",
        "    train = True, # get training data\n",
        "    download = True, # download data if it doesn't exist on disk\n",
        "    transform = Transforms # images come as PIL format, we want to apply transform on them\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False, # get test data\n",
        "    download = True,\n",
        "    transform = Transforms\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyaXLrw2vyAH"
      },
      "source": [
        "## Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eZNDi_wuv24_"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=2,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xc-rMLvZ4HH8"
      },
      "outputs": [],
      "source": [
        "train_sample_batch, train_label_batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0KGXt314Zkr",
        "outputId": "ea2ce74e-bc65-4d36-f039-21745900334a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28]) \n",
            "\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "print(train_sample_batch.shape, '\\n')\n",
        "print(train_label_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "NN7_F5mW4d6w",
        "outputId": "25ddc9c2-4547-4cdb-ae11-12fb62b282d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'A sample image of train data with label=Sandal')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sample_image = train_sample_batch[0].permute(1, 2, 0)\n",
        "label_of_sample_image = train_label_batch[0]\n",
        "\n",
        "mean, std = 0.5, 0.5\n",
        "sample_image = std * (sample_image + mean)\n",
        "\n",
        "plt.imshow(sample_image, cmap='grey')\n",
        "plt.axis('off')\n",
        "plt.title(f'A sample image of train data with label={classes[label_of_sample_image]}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vutHfpK157yf"
      },
      "source": [
        "# Network Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4-CTTp1vxkw"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "[CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HyU2AZaxv1xV"
      },
      "outputs": [],
      "source": [
        "class CNN_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Convolutional Neural Network (CNN) model for image classification.\n",
        "\n",
        "    Architecture:\n",
        "    - Two convolutional layers each followed by Batch Normalization and ReLU activation.\n",
        "    - A MaxPooling layer to downsample the feature maps.\n",
        "    - A classifier consisting of Flatten, Dropout, and a Linear (fully connected) layer\n",
        "      to produce the final output.\n",
        "\n",
        "    Args:\n",
        "        input_channel (int): Number of input channels (e.g., 3 for RGB images).\n",
        "        hidden_unit (int): Number of filters (feature maps) in the convolutional layers.\n",
        "        output_shape (int): Number of classes or output features.\n",
        "\n",
        "    Forward pass:\n",
        "        - Input tensor of shape (batch_size, input_channel, height, width).\n",
        "        - Outputs raw logits of shape (batch_size, output_shape).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_channel, hidden_unit, output_shape):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature extractor: convolutional block\n",
        "        self.CNN_block = nn.Sequential(\n",
        "            # First convolutional layer\n",
        "            nn.Conv2d(in_channels=input_channel, out_channels=hidden_unit, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=hidden_unit),  # Normalize activations for stability and faster convergence\n",
        "            nn.ReLU(inplace=True),                      # Non-linear activation\n",
        "\n",
        "            # Second convolutional layer\n",
        "            nn.Conv2d(in_channels=hidden_unit, out_channels=hidden_unit, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=hidden_unit),  # Batch normalization again\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # MaxPooling to reduce spatial dimensions by factor of 2\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Classifier: fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),       # Flatten feature maps into a vector\n",
        "            nn.Dropout(p=0.5),  # Dropout for regularization to prevent overfitting\n",
        "            nn.Linear(in_features=hidden_unit*14*14, out_features=output_shape)  # Final linear layer for classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Defines the forward computation of the network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, input_channel, height, width).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits of shape (batch_size, output_shape).\n",
        "        \"\"\"\n",
        "        x = self.CNN_block(x)    # Pass input through convolutional feature extractor\n",
        "        x = self.classifier(x)   # Pass extracted features through classifier\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fx9UI12GAhN",
        "outputId": "cf430fd9-8ca6-46d5-aab4-84a2bf80b1b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Model(\n",
              "  (CNN_block): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): Linear(in_features=1960, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = CNN_Model(input_channel=1, hidden_unit=10, output_shape=len(classes))\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhdkaHZEGM_v",
        "outputId": "4aec61ff-0081-4138-db23-02004c89c07d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "random_sample = torch.randn((1, 1, 28, 28))\n",
        "model(random_sample).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl5Tab4LHA8w"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGmYtzKEy_Lh"
      },
      "source": [
        "# Understanding `with` and `tqdm` in Python\n",
        "\n",
        "## `with` statement\n",
        "- Used to wrap the execution of a block with methods defined by a context manager (`__enter__` and `__exit__`).\n",
        "- Ensures proper setup and cleanup (e.g., opening and closing files, managing resources).\n",
        "- Guarantees cleanup even if errors occur inside the block.\n",
        "- Syntax example:\n",
        "  ```python\n",
        "  with open(\"file.txt\", \"r\") as f:\n",
        "      data = f.read()\n",
        "  ```\n",
        "\n",
        "## `tqdm`\n",
        "- A Python library to display progress bars for iterables.\n",
        "- Wraps any iterable (e.g., lists, ranges, DataLoader) to show progress.\n",
        "- Updates progress bar each iteration, showing completion %, elapsed time, estimated time, etc.\n",
        "- Common usage:\n",
        "  ```python\n",
        "  from tqdm import tqdm\n",
        "\n",
        "  for item in tqdm(iterable, desc=\"Processing\"):\n",
        "      # process item\n",
        "      pass\n",
        "  ```\n",
        "- Can be used with `with` to automatically handle progress bar lifecycle:\n",
        "  ```python\n",
        "  with tqdm(iterable, desc=\"Processing\") as pbar:\n",
        "      for item in pbar:\n",
        "          # process item\n",
        "          pass\n",
        "  ```\n",
        "- When wrapping a DataLoader, tqdm tracks progress over **all batches**, not individual samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LRH9EGguHHlU"
      },
      "outputs": [],
      "source": [
        "def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device):\n",
        "    \"\"\"\n",
        "    Performs one full training epoch over the provided data loader.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model to train.\n",
        "        data_loader (DataLoader): DataLoader providing training batches.\n",
        "        loss_fn (callable): Loss function to compute the error.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for updating model parameters.\n",
        "        accuracy_fn (callable): Function to calculate accuracy.\n",
        "        device (torch.device): Device to run computations on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_train_loss, average_train_accuracy) over the epoch.\n",
        "    \"\"\"\n",
        "    model.to(device)  # Move model to the specified device (CPU or GPU)\n",
        "    train_loss, train_acc, counter = 0, 0, 0\n",
        "\n",
        "    with tqdm(data_loader, desc='  train') as train_tqdm:\n",
        "        for X, y in train_tqdm:\n",
        "            # Move data to the specified device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass: predict outputs\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Compute the loss for current batch\n",
        "            loss = loss_fn(y_pred, y)\n",
        "\n",
        "            # Accumulate loss and accuracy values\n",
        "            train_loss += loss.item()  # Convert tensor loss to float before accumulating\n",
        "            train_acc += accuracy_fn(true=y.cpu(), pred=y_pred.cpu())\n",
        "\n",
        "            counter += 1  # Increment batch counter\n",
        "\n",
        "            # Update tqdm progress bar postfix with current average accuracy and loss\n",
        "            train_tqdm.set_postfix(\n",
        "                train_acc=train_acc / counter,\n",
        "                train_loss=train_loss / counter,\n",
        "                refresh=True\n",
        "            )\n",
        "\n",
        "            # Zero gradients before backward pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass: compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update model parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        # Compute average loss and accuracy over all batches\n",
        "        train_loss /= len(data_loader)\n",
        "        train_acc /= len(data_loader)\n",
        "\n",
        "    return train_loss, train_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypMuKqcr40Gl"
      },
      "source": [
        "# Test Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iGD9_zCpir5i"
      },
      "outputs": [],
      "source": [
        "def test_step(model, data_loader, loss_fn, accuracy_fn, device):\n",
        "    \"\"\"\n",
        "    Evaluate a trained model on a test dataset.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained PyTorch model to evaluate.\n",
        "        data_loader (torch.utils.data.DataLoader): DataLoader containing the test dataset.\n",
        "        loss_fn (callable): Loss function used to compute the evaluation loss.\n",
        "        accuracy_fn (callable): Function to compute accuracy.\n",
        "                                 Should accept `true` (ground truth labels) and `pred` (model predictions).\n",
        "        device (torch.device or str): Device to perform computation on ('cpu' or 'cuda').\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            test_loss (float) - Average loss over the test dataset.\n",
        "            test_acc (float) - Average accuracy over the test dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Move the model to the specified device (CPU or GPU)\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize accumulators for loss, accuracy, and batch count\n",
        "    test_loss, test_acc, counter = 0, 0, 0\n",
        "\n",
        "    # Set the model to evaluation mode (important for layers like dropout, batch norm)\n",
        "    model.eval()\n",
        "\n",
        "    # Use tqdm for a progress bar over the test DataLoader\n",
        "    with tqdm(data_loader, desc='  test') as test_tqdm:\n",
        "        for X, y in test_tqdm:\n",
        "            # Move input data and labels to the selected device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass (no gradient calculation needed for testing)\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss (detach from computation graph)\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "\n",
        "            # Accumulate accuracy (move predictions and labels back to CPU for calculation)\n",
        "            test_acc += accuracy_fn(true=y.cpu(), pred=test_pred.cpu())\n",
        "\n",
        "            # Keep track of processed batches\n",
        "            counter += 1\n",
        "\n",
        "            # Update the progress bar display\n",
        "            test_tqdm.set_postfix(\n",
        "                test_acc=test_acc / counter,\n",
        "                test_loss=test_loss / counter,\n",
        "                refresh=True\n",
        "            )\n",
        "\n",
        "        # Compute the average loss and accuracy over all batches\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "\n",
        "    return test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx2he-a-j6DI"
      },
      "source": [
        "# Main loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RBwG6ZbWkVNt"
      },
      "outputs": [],
      "source": [
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "def accuracy_fn(true, pred):\n",
        "    pred = F.softmax(pred, dim=1)\n",
        "    pred = torch.argmax(pred, dim=1)\n",
        "    # true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(dim=1, index=true.unsqueeze(dim=1), value=1.0)\n",
        "    # true = torch.argmax(true, dim=1)\n",
        "    return torch.mean((pred == true).float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BtFD65p8opwG"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o81Uqzu_xhLg",
        "outputId": "f217d176-844b-4dce-eec4-aec91530ed54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:22<00:00, 84.39it/s, train_acc=tensor(0.7720), train_loss=0.645]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 97.27it/s, test_acc=tensor(0.8477), test_loss=tensor(0.4270, device='cuda:0')] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 2/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 92.80it/s, train_acc=tensor(0.8709), train_loss=0.362]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 81.78it/s, test_acc=tensor(0.8617), test_loss=tensor(0.3889, device='cuda:0')] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 3/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 90.39it/s, train_acc=tensor(0.8894), train_loss=0.314] \n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 86.44it/s, test_acc=tensor(0.8820), test_loss=tensor(0.3272, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 4/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 91.66it/s, train_acc=tensor(0.8983), train_loss=0.286] \n",
            "  test: 100%|██████████| 313/313 [00:02<00:00, 106.30it/s, test_acc=tensor(0.8829), test_loss=tensor(0.3279, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 5/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 89.20it/s, train_acc=tensor(0.9052), train_loss=0.269]\n",
            "  test: 100%|██████████| 313/313 [00:02<00:00, 109.25it/s, test_acc=tensor(0.8888), test_loss=tensor(0.3116, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 6/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:19<00:00, 94.78it/s, train_acc=tensor(0.9097), train_loss=0.255] \n",
            "  test: 100%|██████████| 313/313 [00:04<00:00, 75.93it/s, test_acc=tensor(0.8919), test_loss=tensor(0.2981, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 7/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 93.45it/s, train_acc=tensor(0.9136), train_loss=0.243]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 101.16it/s, test_acc=tensor(0.8950), test_loss=tensor(0.2958, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 8/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 86.58it/s, train_acc=tensor(0.9173), train_loss=0.232]\n",
            "  test: 100%|██████████| 313/313 [00:02<00:00, 104.51it/s, test_acc=tensor(0.8974), test_loss=tensor(0.2947, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 9/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 88.45it/s, train_acc=tensor(0.9202), train_loss=0.224]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 97.72it/s, test_acc=tensor(0.8985), test_loss=tensor(0.2936, device='cuda:0')] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 10/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 92.44it/s, train_acc=tensor(0.9228), train_loss=0.217]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 78.68it/s, test_acc=tensor(0.9008), test_loss=tensor(0.2837, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 11/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 91.63it/s, train_acc=tensor(0.9251), train_loss=0.21] \n",
            "  test: 100%|██████████| 313/313 [00:02<00:00, 104.37it/s, test_acc=tensor(0.9013), test_loss=tensor(0.2843, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 12/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 88.41it/s, train_acc=tensor(0.9272), train_loss=0.204] \n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 101.21it/s, test_acc=tensor(0.9004), test_loss=tensor(0.2864, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 13/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 87.76it/s, train_acc=tensor(0.9282), train_loss=0.199]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 102.43it/s, test_acc=tensor(0.9031), test_loss=tensor(0.2871, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 14/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 92.72it/s, train_acc=tensor(0.9311), train_loss=0.194]\n",
            "  test: 100%|██████████| 313/313 [00:04<00:00, 75.23it/s, test_acc=tensor(0.9036), test_loss=tensor(0.2831, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 15/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 92.55it/s, train_acc=tensor(0.9319), train_loss=0.189]\n",
            "  test: 100%|██████████| 313/313 [00:02<00:00, 106.31it/s, test_acc=tensor(0.9014), test_loss=tensor(0.2865, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 16/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 87.70it/s, train_acc=tensor(0.9337), train_loss=0.185] \n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 101.21it/s, test_acc=tensor(0.9034), test_loss=tensor(0.2814, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 17/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 88.49it/s, train_acc=tensor(0.9360), train_loss=0.18]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 95.20it/s, test_acc=tensor(0.9050), test_loss=tensor(0.2862, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 18/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 92.96it/s, train_acc=tensor(0.9362), train_loss=0.178]\n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 78.54it/s, test_acc=tensor(0.9046), test_loss=tensor(0.2834, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 19/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:20<00:00, 91.96it/s, train_acc=tensor(0.9370), train_loss=0.175] \n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 103.27it/s, test_acc=tensor(0.9032), test_loss=tensor(0.3013, device='cuda:0')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 20/20 :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  train: 100%|██████████| 1875/1875 [00:21<00:00, 87.21it/s, train_acc=tensor(0.9392), train_loss=0.171] \n",
            "  test: 100%|██████████| 313/313 [00:03<00:00, 103.83it/s, test_acc=tensor(0.9048), test_loss=tensor(0.2891, device='cuda:0')]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 482.815 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_epoch_loss = []\n",
        "train_epoch_accuracy = []\n",
        "test_epoch_loss = []\n",
        "test_epoch_accuracy = []\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    print(f\"EPOCH {epoch + 1}/{epochs} :\")\n",
        "\n",
        "    # Training step\n",
        "    train_loss, train_acc = train_step(\n",
        "        model=model,\n",
        "        data_loader=train_loader,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Test step (no grad to save memory)\n",
        "    with torch.no_grad():\n",
        "        test_loss, test_acc = test_step(\n",
        "            model=model,\n",
        "            data_loader=test_loader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    # Store results (convert to CPU before appending)\n",
        "    train_epoch_loss.append(train_loss.item() if torch.is_tensor(train_loss) else train_loss)\n",
        "    train_epoch_accuracy.append(train_acc.item() if torch.is_tensor(train_acc) else train_acc)\n",
        "    test_epoch_loss.append(test_loss.item() if torch.is_tensor(test_loss) else test_loss)\n",
        "    test_epoch_accuracy.append(test_acc.item() if torch.is_tensor(test_acc) else test_acc)\n",
        "\n",
        "    # Free GPU memory\n",
        "    del train_loss, train_acc, test_loss, test_acc\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "end_time = timer()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total training time: {total_time:.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'saved_model')"
      ],
      "metadata": {
        "id": "CcOMHL5Kp5C_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66yQ0dE4p8iS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNaP2yWm6uwx+ez2pcK7q+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}